{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "preprocess_data.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5D6TsQlvSZH"
      },
      "source": [
        "# [Data Preprocessing](http://colab.research.google.com/github/boringPpl/presidential_debates_comments_clustering/blob/main/preprocess_data.ipynb)\n",
        "\n",
        "## 1. Setup\n",
        "\n",
        "### 1.1 Hardware\n",
        "\n",
        "First, check that the runtime in Google Colab is set to GPU. If it is not, go to **Runtime > Change runtime type** and change the **Hardware Accelerator** to **GPU**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsSzCZyxy9As",
        "outputId": "0f7d7d65-18c5-4051-c7c7-fbefcb991ce3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Mar 29 12:11:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f99sNEh2bnr"
      },
      "source": [
        "The following shows the CPU details for the Google Colab instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klKuW-xB2FKl",
        "outputId": "d910febe-975b-4d45-8387-15205c14c029"
      },
      "source": [
        "!lscpu"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2199.998\n",
            "BogoMIPS:            4399.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN3t5qwA2rbb"
      },
      "source": [
        "The memory available for the instance is listed as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46fl6M1z2IVk",
        "outputId": "66c8367a-e797-407e-c910-ada6b94be076"
      },
      "source": [
        "!free -h"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        579M         10G        1.0M        2.0G         11G\n",
            "Swap:            0B          0B          0B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FT94kk61QKd"
      },
      "source": [
        "### 1.2 Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49kLid8avSZJ",
        "outputId": "46c76210-820c-4726-de61-88b6d044864a"
      },
      "source": [
        "!git clone https://github.com/boringPpl/presidential_debates_comments_clustering.git\n",
        "%cd presidential_debates_comments_clustering\n",
        "!pip install -qr requirements.txt"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'presidential_debates_comments_clustering'...\n",
            "remote: Enumerating objects: 140, done.\u001b[K\n",
            "remote: Counting objects: 100% (140/140), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 140 (delta 64), reused 84 (delta 27), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (140/140), 44.08 MiB | 26.29 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "/content/presidential_debates_comments_clustering/presidential_debates_comments_clustering\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZevAggEvSZK"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import emoji\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "embedder = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGSugYCGvSZK"
      },
      "source": [
        "## 2. Exploratory Data Analysis\n",
        "\n",
        "### 2.1 Load data into Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWRl3_GzvSZK"
      },
      "source": [
        "def load_comments(video_id):\n",
        "    filename = f'data/{video_id}_csv_final.feather'\n",
        "    df = pd.read_feather(filename)\n",
        "    return df"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLffUHsTvSZL"
      },
      "source": [
        "# This is the dataset for the first presidential debate.\n",
        "df1 = load_comments('wW1lY5jFNcQ')\n",
        "comments1 = df1['Comments']\n",
        "df1['Updated At'] = pd.to_datetime(df1['Updated At'], format='%Y-%m-%dT%H:%M:%SZ', errors='coerce')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNpUIfUnvSZL"
      },
      "source": [
        "### 2.2 Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "bnHLsvy7vSZL",
        "outputId": "02ec1a78-ec94-486b-960e-5c2ea735ec53"
      },
      "source": [
        "print(f'The shape of the dataframe is: {df1.shape}')\n",
        "print(f\"The time range for the data is: {df1['Updated At'].min():%Y-%m-%d %H%Mh} to {df1['Updated At'].max():%Y-%m-%d %H%Mh}\")\n",
        "df1.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the dataframe is: (53271, 6)\n",
            "The time range for the data is: 2020-09-30 0245h to 2021-03-28 1717h\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Comment ID</th>\n",
              "      <th>Reply Count</th>\n",
              "      <th>Like Count</th>\n",
              "      <th>Updated At</th>\n",
              "      <th>Viewer Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Trump's America: *7M cases*\\nBiden: 200K peopl...</td>\n",
              "      <td>UgzOHAjMxYA4Q1NXivR4AaABAg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-28 17:17:10</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wow Joes laugh makes me cringe 😬</td>\n",
              "      <td>Ugy1AdZUVDPjO-YzszB4AaABAg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-28 09:49:51</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dang hate to say it,  Trump seems sharp compar...</td>\n",
              "      <td>UgwxiTXgqmNvg0nQZ554AaABAg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-28 09:48:46</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HEY BIDEN, I HAVE A FEELING YOU WERE IN ON THE...</td>\n",
              "      <td>UgyjoIPRCH0X57xnKa94AaABAg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-27 15:16:51</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FAKE BRIDEN!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!...</td>\n",
              "      <td>UgxXf4RANq3Per7_lKR4AaABAg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-27 15:15:17</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments  ... Viewer Rating\n",
              "0  Trump's America: *7M cases*\\nBiden: 200K peopl...  ...          none\n",
              "1                   Wow Joes laugh makes me cringe 😬  ...          none\n",
              "2  Dang hate to say it,  Trump seems sharp compar...  ...          none\n",
              "3  HEY BIDEN, I HAVE A FEELING YOU WERE IN ON THE...  ...          none\n",
              "4  FAKE BRIDEN!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!...  ...          none\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "2lhHs12yvSZL",
        "outputId": "59ec4947-1df8-4bbe-9e57-ed344e5a22bf"
      },
      "source": [
        "ax = df1['Updated At'].hist(bins=25, figsize=(12, 5))\n",
        "ax.set_yscale('log')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZyIA-tfvSZM",
        "outputId": "2984d347-a8b6-429a-ded9-7cce16ce54a9"
      },
      "source": [
        "import emoji\n",
        "print(emoji.demojize('trending 😉\t'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trending :winking_face:\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lej-nAeXvSZM"
      },
      "source": [
        "df_corpus = df1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWq6agYPvSZM"
      },
      "source": [
        "df_corpus.rename(columns={'Comments': 'comment_text'}, inplace=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvynIneBvSZN"
      },
      "source": [
        "# De-emojize\n",
        "df_corpus['comments_cleaned'] = df_corpus['comment_text'].apply(emoji.demojize)\n",
        "\n",
        "# Replace the colons, and \\n with a space\n",
        "df_corpus['comments_cleaned'] = df_corpus['comments_cleaned'].str.replace('[\\n:]', ' ', regex=True)\n",
        "df_corpus['comments_cleaned'] = df_corpus['comments_cleaned'].str.replace(r'\\\\n', ' ', regex=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iwHuvFPvSZN"
      },
      "source": [
        "df_corpus['comments_cleaned'] = df_corpus['comments_cleaned'].str.lower()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YxEPBoTvSZN",
        "outputId": "40a9b626-ce42-46f0-8154-4d75d102679e"
      },
      "source": [
        "df_corpus.drop_duplicates(subset=['comments_cleaned'], inplace = True)\n",
        "df_corpus.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50889, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEWnr931vSZO"
      },
      "source": [
        "# remove special characters\n",
        "df_corpus['comments_cleaned'] = df_corpus['comments_cleaned'].str.replace('[^a-zA-Z0-9]', ' ')\n",
        "\n",
        "# remove white spaces\n",
        "df_corpus['comments_cleaned'] = df_corpus['comments_cleaned'].str.replace('\\s+', ' ', regex=True)\n",
        "df_corpus['comments_cleaned'] = df_corpus['comments_cleaned'].str.strip()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1DNb4RIvSZO"
      },
      "source": [
        "df_corpus['comments_cleaned'].to_csv('meta.tsv', columns=['comments_cleaned'], index= False, header= False)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX6NhMd5vSZO"
      },
      "source": [
        "The longest comment has 16120 characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XEek6ClvSZP",
        "outputId": "fe3805d8-6203-4f6d-d5b9-fec00bc70694"
      },
      "source": [
        "df_corpus['comments_cleaned'].apply(len).sort_values(ascending=False).head(20)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17433    16120\n",
              "34534    10709\n",
              "33397     9944\n",
              "2455      9649\n",
              "15230     9594\n",
              "41574     9539\n",
              "16652     9261\n",
              "29426     8957\n",
              "5256      8910\n",
              "16754     8711\n",
              "2614      8534\n",
              "22371     8399\n",
              "37653     7883\n",
              "47314     7336\n",
              "25375     7324\n",
              "42454     7260\n",
              "19705     7145\n",
              "27632     7129\n",
              "16743     6957\n",
              "26948     6955\n",
              "Name: comments_cleaned, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcv7vIhgvSZP"
      },
      "source": [
        "## Sentence Bert Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZboLRN5vSZP"
      },
      "source": [
        "corpus_embeddings = embedder.encode(df_corpus[\"comments_cleaned\"].values.tolist())"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UcZAIVdvSZP",
        "outputId": "ac6dffc2-e3c0-406e-d1a0-c4aaa0813109"
      },
      "source": [
        "corpus_embeddings = np.array(corpus_embeddings)\n",
        "corpus_embeddings.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50889, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfBQw8jWvSZP"
      },
      "source": [
        "def plot_similarity(labels, features, rotation):\n",
        "  corr = np.inner(features, features)\n",
        "  sns.set(font_scale=1.2)\n",
        "  g = sns.heatmap(\n",
        "      corr,\n",
        "      xticklabels=labels,\n",
        "      yticklabels=labels,\n",
        "      vmin=0,\n",
        "      vmax=1,\n",
        "      cmap=\"YlOrRd\")\n",
        "  g.set_xticklabels(labels, rotation=rotation)\n",
        "  g.set_title(\"Semantic Textual Similarity\")\n",
        "\n",
        "def run_and_plot(messages_):\n",
        "  message_embeddings_ = embed(messages_)\n",
        "  plot_similarity(messages_, corpus_embeddings, 90)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDMPsKE5vSZQ"
      },
      "source": [
        "## Google Universal Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd-JU_exvSZQ",
        "outputId": "eae50ebc-bfaf-4580-ce7a-7944c4c91ca3"
      },
      "source": [
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
        "model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "def embed(input):\n",
        "  return model(input)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/5'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder-large/5, Total size: 577.10MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/5'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder-large/5 loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "img28FjgvSZQ",
        "outputId": "2742fe7a-7339-4885-914f-504601d8ca75"
      },
      "source": [
        "#@title Compute a representation for each message, showing various lengths supported.\n",
        "word = \"Elephant\"\n",
        "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
        "paragraph = (\n",
        "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
        "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
        "    \"the more 'diluted' the emtbedding will be.\")\n",
        "messages = [word, sentence, paragraph]\n",
        "\n",
        "# Reduce logging output.\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "message_embeddings = embed(messages)\n",
        "\n",
        "for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
        "  print(\"Message: {}\".format(messages[i]))\n",
        "  print(\"Embedding size: {}\".format(len(message_embedding)))\n",
        "  message_embedding_snippet = \", \".join(\n",
        "      (str(x) for x in message_embedding[:3]))\n",
        "  print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message: Elephant\n",
            "Embedding size: 512\n",
            "Embedding: [-0.03458559885621071, -0.01799013465642929, 0.0019805855117738247, ...]\n",
            "\n",
            "Message: I am a sentence for which I would like to get its embedding.\n",
            "Embedding size: 512\n",
            "Embedding: [0.05833391845226288, -0.0818500891327858, 0.06890938431024551, ...]\n",
            "\n",
            "Message: Universal Sentence Encoder embeddings also support short paragraphs. There is no hard limit on how long the paragraph is. Roughly, the longer the more 'diluted' the emtbedding will be.\n",
            "Embedding size: 512\n",
            "Embedding: [-0.01888345181941986, -0.003110897494480014, -0.03367341309785843, ...]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFNDvKCSvSZQ"
      },
      "source": [
        "## Semantic Textual Similarity Task Example\n",
        "\n",
        "The embeddings produced by the Universal Sentence Encoder are approximately normalized. The semantic similarity of two sentences can be trivially computed as the inner product of the encodings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyhhupo_vSZR"
      },
      "source": [
        "def plot_similarity(labels, features, rotation):\n",
        "  corr = np.inner(features, features)\n",
        "  sns.set(font_scale=1.2)\n",
        "  g = sns.heatmap(\n",
        "      corr,\n",
        "      xticklabels=labels,\n",
        "      yticklabels=labels,\n",
        "      vmin=0,\n",
        "      vmax=1,\n",
        "      cmap=\"YlOrRd\")\n",
        "  g.set_xticklabels(labels, rotation=rotation)\n",
        "  g.set_title(\"Semantic Textual Similarity\")\n",
        "\n",
        "def run_and_plot(messages_):\n",
        "  message_embeddings_ = embed(messages_)\n",
        "  plot_similarity(messages_, message_embeddings_, 90)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKYBmWgwvSZR"
      },
      "source": [
        "messages0 = df_corpus[\"comments_cleaned\"].values.tolist()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBn-kGVuvSZR",
        "outputId": "30efb3c6-97fa-4041-8a9e-e9851388f154"
      },
      "source": [
        "df_corpus[\"comments_cleaned\"].apply(len).max()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF4xETc3vSZS"
      },
      "source": [
        "# embeddings_long = embed([df_corpus['comments_cleaned'].loc[617593]])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOe8pabYvSZS"
      },
      "source": [
        "# [USComments.csv] Take only the first 2200 characters of each comment. Crashes at 2300+\n",
        "# [Presidential Debate 1] < 2200. Trying 2000 [Nope]. Trying 1800 [Nope].\n",
        "# Trying 1000 [Nope]. Trying 500 [Nope]. Trying 200.\n",
        "max_chars = 200\n",
        "messages = df_corpus[\"comments_cleaned\"].apply(\n",
        "    lambda x: x[:max_chars]\n",
        ").values.tolist()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL93dJEI51OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05fb12fc-ff21-4e7b-b395-4d6f5e62902d"
      },
      "source": [
        "print('Embeddings can only be done with about 500 rows at a time')\n",
        "n_chunks = len(messages) // 500\n",
        "message_list = np.array_split(np.array(messages), n_chunks)\n",
        "print(f'The {len(messages)} messages will be divided into {n_chunks} chunks of approximately 500 rows per chunk')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embeddings can only be done with about 500 rows at a time\n",
            "The 50889 messages will be divided into 101 chunks of approximately 500 rows per chunk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEr9Lh407TV_"
      },
      "source": [
        "for i, message in enumerate(message_list):\n",
        "    if i == 0:\n",
        "        embeddings = embed(message).numpy()\n",
        "    else:\n",
        "        embedding = embed(message).numpy()\n",
        "        embeddings = np.vstack((embeddings, embedding))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoqTDzWd8D2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52ae1be-09ef-4ab7-aff7-e4a5f86ce33d"
      },
      "source": [
        "print(f'The embeddings numpy array has shape: {embeddings.shape}')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The embeddings numpy array has shape: (50889, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X2OiSSj26FO"
      },
      "source": [
        "Saving 47k rows of data will take a long time (the final size is 588MB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_QCoFe2vSZS"
      },
      "source": [
        "np.savetxt('vecs0.tsv', embeddings , delimiter=\"\\t\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70st8gsRAh0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcfc979-daac-4768-bed8-ec353485c962"
      },
      "source": [
        "# Check the final size of the file\n",
        "!ls -lh vecs.tsv"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'vecs.tsv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlBGndw4vSZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34267b08-5041-47d4-8949-8ad0f30b38d6"
      },
      "source": [
        "pd.Series(messages).apply(len).max()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH6VTjAVvSZV"
      },
      "source": [
        "### PCA reduction\n",
        "\n",
        "The size of `vecs.tsv` can be reduced further.\n",
        "Using PCA, the number of dimensions of each embedding is reduced from 512 to 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gso-q5SPvSZV"
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8e9cd7JvSZV"
      },
      "source": [
        "#scale the data 0-1\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "rescaled = scaler.fit_transform(embeddings)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLfDLcITvSZV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ca7ca667-ae3a-4d3b-a88a-3f60f6d5fc30"
      },
      "source": [
        "pca = PCA().fit(rescaled)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance');"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4qYCfpbvSZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea04fb6f-0780-4c4e-f2fa-d738c82589e9"
      },
      "source": [
        "# need around 200 components to describe 100% of variance\n",
        "pca = PCA(n_components = 50)\n",
        "reduced_embeds = pca.fit_transform(rescaled)\n",
        "print(\"Original shape:   \", rescaled.shape)\n",
        "print(\"Transformed shape:\", reduced_embeds.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape:    (50889, 512)\n",
            "Transformed shape: (50889, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMYogewKvSZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329abccb-2942-4c9e-b98b-b061cf424228"
      },
      "source": [
        "pca = PCA(n_components = 50)\n",
        "reduced_embeds = pca.fit_transform(rescaled)\n",
        "reduced_embeds.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50889, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVexQw8e9UYT"
      },
      "source": [
        "np.savetxt('vecs.tsv', reduced_embeds , delimiter=\"\\t\")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H6f_9ZR-Z3w"
      },
      "source": [
        "After dimension reduction using PCA, the file size has been reduced from 588 MB to 58 MB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubaCiKEK9bNe",
        "outputId": "abda22f8-4852-4f53-b0f9-1e4a01afd1d5"
      },
      "source": [
        "!ls -lh vecs*.tsv"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 634M Mar 29 13:07 vecs0.tsv\n",
            "-rw-r--r-- 1 root root  62M Mar 29 13:07 vecs.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwHbLUzpvSZW"
      },
      "source": [
        "## Run HDBScan to find the clusters\n",
        "\n",
        "Note: the next code block takes a long time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVxDNTW4vSZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "424f5879-a84e-4554-d91c-7ede5ccacb8f"
      },
      "source": [
        "import hdbscan\n",
        "\n",
        "clusterer = hdbscan.HDBSCAN()\n",
        "clusterer.fit(reduced_embeds)\n",
        "clusterer.labels_"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -1, 117,  -1, ...,  -1,  -1,  -1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdzdxO4gvSZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3042d0bf-6f74-4b7c-9924-ce515578579f"
      },
      "source": [
        "clusterer.labels_.max()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuyjHVj7vSZX"
      },
      "source": [
        "df_corpus['hdb_labels'] = clusterer.labels_"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItoZ2c79vSZX"
      },
      "source": [
        "# df_corpus.to_csv('meta_lab.tsv', columns=['comments_cleaned','hdb_labels'], index= False, header= True, sep='\\t')\n",
        "df_corpus.to_csv('meta_lab.tsv', columns=['comment_text','hdb_labels'], index= False, header= True, sep='\\t')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGK0xEcJvSZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffdc5764-8c9f-4e9e-a19e-4b1866c8b5a3"
      },
      "source": [
        "!head -5 meta.tsv"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trump s america 7m cases biden 200k people have already died under his rule biden s america 30m cases 500k deaths biden well sometimes we fall and rise again\n",
            "wow joes laugh makes me cringe grimacing face\n",
            "dang hate to say it trump seems sharp compared to biden recently\n",
            "hey biden i have a feeling you were in on the scandal in new york to make trump look bad make more deaths on his watch\n",
            "fake briden look what he is doing to america\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVw6ZMisvSZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8f7cc6-a216-44ca-e2cb-71e24f44c3ce"
      },
      "source": [
        "!head -5 meta_lab.tsv"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comment_text\thdb_labels\n",
            "\"Trump's America: *7M cases*\n",
            "Biden: 200K people have already died under his rule!\n",
            "\n",
            "Biden's America: *30M CASES+500K deaths*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcb3V6wK5ahi",
        "outputId": "e0673341-2fd7-48a5-fec5-9ccd7b8c64fc"
      },
      "source": [
        "!ls -lh *.tsv"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 6.1M Mar 29 13:10 meta_lab.tsv\n",
            "-rw-r--r-- 1 root root 5.9M Mar 29 13:03 meta.tsv\n",
            "-rw-r--r-- 1 root root 634M Mar 29 13:07 vecs0.tsv\n",
            "-rw-r--r-- 1 root root  62M Mar 29 13:07 vecs.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh1NbTfbvSZY"
      },
      "source": [
        "Save`vecs.tsv` and `meta_lab.tsv` and navigate to http://projector.tensorflow.org/. Press \"Load\" and use `vecs.tsv` for the first file, and `meta_lab.tsv` for the second file. Downloading files from Google Colab can take a while. For faster downloading, `vecs.tsv` has been compressed as `vecs.tar.bz2` (file reduction from 58 MB to 20 MB)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV4wksXQ-_TT",
        "outputId": "70183c17-b09e-4686-ea63-353cc225d37c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!tar -cjf vecs.tar.bz2 vecs.tsv\n",
        "!ls -lh vecs.tar.bz2"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 22M Mar 29 13:10 vecs.tar.bz2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HLvTekSvSZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ee24386b-46fc-4d8a-f81b-b09da485f7a0"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('vecs.tar.bz2')\n",
        "files.download('meta_lab.tsv')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_800b238e-7a73-47f1-a484-93432edb43c3\", \"vecs.tar.bz2\", 22175486)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_fd4b367d-2837-4e3f-a8e7-c2cad3dfb044\", \"meta_lab.tsv\", 6370426)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvxWaEeEFlKP"
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": []
    }
  ]
}